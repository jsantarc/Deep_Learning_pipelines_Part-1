{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
    "</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Convolutional Neural Network with Data Augmentation </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<p>In this lab, we train a Convolutional Neural Network with Regular data and Augmented data. We will show that the Augmented data imporoves improves generalization performance. </p>\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"#Makeup_Data\">Get Some Data</a></li>\n",
    "<li><a href=\"#CNN\">Convolutional Neural Network</a></li>\n",
    "<li><a href=\"#R_training_data\">Rotated Training Data</a></li>\n",
    "\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>25 min</strong> 14 min to train model </p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/meet_up/12.02.2020/normal.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/meet_up/12.02.2020/rotated_data.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow==6.2.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/2f/f30f3d7af9e46e2b6e45bb85300a07eb98410721ba376f555b7c3dce8916/Pillow-6.2.2-cp36-cp36m-macosx_10_6_intel.whl (3.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.9MB 8.5MB/s \n",
      "\u001b[?25hInstalling collected packages: Pillow\n",
      "  Found existing installation: Pillow 5.4.1\n",
      "    Uninstalling Pillow-5.4.1:\n",
      "      Successfully uninstalled Pillow-5.4.1\n",
      "Successfully installed Pillow-6.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow==6.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Restart the kernel***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import the libraries we need to use in this lab\n",
    "# Using the following line code to install the torchvision library\n",
    "# !conda install -y torchvision\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import torchvision.datasets as dsets\n",
    "import os  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful functions for plotting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot cost and accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost_accuracy(checkpoint):\n",
    "\n",
    "# Plot the cost and accuracy\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:red'\n",
    "    ax1.plot(checkpoint['cost'], color=color)\n",
    "    ax1.set_xlabel('epoch', color=color)\n",
    "    ax1.set_ylabel('Cost', color=color)\n",
    "    ax1.tick_params(axis='y', color=color)\n",
    "    \n",
    "    ax2 = ax1.twinx()  \n",
    "    color = 'tab:blue'\n",
    "    ax2.set_ylabel('accuracy', color=color) \n",
    "    ax2.set_xlabel('epoch', color=color)\n",
    "    ax2.plot( checkpoint['accuracy'], color=color)\n",
    "    ax2.tick_params(axis='y', color=color)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function <code>show_data</code> to plot out data samples as images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def show_data(data_sample):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n",
    "    plt.title('y = '+ str(data_sample[1].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Plot misclassified samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_mis_classified(model,dataset):\n",
    "    count=0\n",
    "    for x, y in torch.utils.data.DataLoader(dataset=dataset, batch_size=1):\n",
    "        z = model(x)\n",
    "        _, yhat = torch.max(z, 1)\n",
    "        if yhat != y:\n",
    "            show_data((x, y))\n",
    "            plt.show()\n",
    "            count += 1\n",
    "        if count >= 5:\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Makeup_Data\">Load Data</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we create a transform object  <code> compose </code> one will resize the image and convert it to a tensor, the second will also rotate the image Randomly rotate the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 16\n",
    "\n",
    "compose_rotate = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),transforms.RandomAffine(45), transforms.ToTensor()])\n",
    "compose = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training dataset by setting the parameters <code>train </code> to <code>True</code>. We use the transform defined above, one with rotated data one without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset_rotate = dsets.MNIST(root='./data', train=True, download=True, transform=compose_rotate)\n",
    "train_dataset = dsets.MNIST(root='./data', train=True, download=True, transform=compose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the testing dataset by setting the parameters train  <code>False</code>, where the data is <b>ALL</b> rotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Make the validating \n",
    "\n",
    "validation_dataset = dsets.MNIST(root='./data', train=False, download=True, transform=compose_rotate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the data type is long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Show the data type for each element in dataset\n",
    "\n",
    "train_dataset[0][1].type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element in the rectangular tensor corresponds to a number representing a pixel intensity as demonstrated by the following image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.2.1imagenet.png\" width=\"550\" alt=\"MNIST data image\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the fourth label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The label for the fourth data element\n",
    "\n",
    "train_dataset[3][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the fourth sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The image for the fourth data element\n",
    "show_data(train_dataset[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_data(train_dataset_rotate[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth sample is a \"1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"CNN\">Build a Convolutional Neural Network Class</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Convolutional Network class with two Convolutional layers and one fully connected layer. Pre-determine the size of the final output matrix. The parameters in the constructor are the number of output channels for the first and second layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    # Contructor\n",
    "    def __init__(self, out_1=16, out_2=32):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, stride=1, padding=2)\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(out_2 * 4 * 4, 10)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    # Outputs in each steps\n",
    "    def activations(self, x):\n",
    "        #outputs activation this is not necessary\n",
    "        z1 = self.cnn1(x)\n",
    "        a1 = torch.relu(z1)\n",
    "        out = self.maxpool1(a1)\n",
    "        \n",
    "        z2 = self.cnn2(out)\n",
    "        a2 = torch.relu(z2)\n",
    "        out1 = self.maxpool2(a2)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        return z1, a1, z2, a2, out1,out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"regular_data\">Regular Data</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Convolutional Neural Network Classifier, Criterion function, Optimizer and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the model object using CNN class\n",
    "\n",
    "model = CNN(out_1=16, out_2=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model parameters for the kernels before training the kernels. The kernels are initialized randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function, the optimizer and the dataset loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will train the model, we will comment it out as it takes a long time to run. You can load the trained model in the next cell."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "import os  \n",
    "    \n",
    "file_normal=os.path.join(os.getcwd(),'normal.pt')\n",
    "\n",
    "\n",
    "checkpoint={\n",
    "            'epoch':None,\n",
    "            'model_state_dict':None ,\n",
    "            'optimizer_state_dict':None,\n",
    "            'loss':None ,\n",
    "            'cost':[],\n",
    "            'accuracy':[]}\n",
    "n_epochs = 5\n",
    "\n",
    "N_test = len(validation_dataset)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    counter = 0\n",
    "    cost=0\n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        z = model(x)\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter = counter+1\n",
    "      \n",
    "            \n",
    "        checkpoint['epochs']=n_epochs\n",
    "        checkpoint['model_state_dict']=model.state_dict()\n",
    "        checkpoint['optimizer_state_dict']= optimizer.state_dict()\n",
    "        checkpoint['loss']=loss\n",
    "        cost+=loss.item()\n",
    "        \n",
    "     \n",
    "            \n",
    "    correct = 0\n",
    "        \n",
    "        #perform a prediction on the validation  data  \n",
    "    for x_test, y_test in validation_loader:\n",
    "        z = model(x_test)\n",
    "        _, yhat = torch.max(z.data, 1)\n",
    "        correct += (yhat == y_test).sum().item()\n",
    "    accuracy = correct / N_test\n",
    "    print(accuracy)\n",
    "    checkpoint['cost'].append(cost) \n",
    "    checkpoint['accuracy'].append(accuracy)\n",
    "    torch.save(checkpoint, file_normal) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Result\">Analyze Results</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_normal = torch.load(os.path.join(os.getcwd(),'normal.pt'))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot accuracy and cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_accuracy(checkpoint_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "five misclassified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint_normal['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "plot_mis_classified(model,validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"R_training_data\">Rotated Training Data</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss and accuracy on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r = CNN(out_1=16, out_2=32)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model_r.parameters(), lr = learning_rate)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset_rotate, batch_size=100)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will train the model, we will comment it out as it takes a long time to run. You can load the trained model in the next cell."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "file_rotated=os.path.join(os.getcwd(),'rotated_data.pt')\n",
    "\n",
    "\n",
    "checkpoint_rotated={\n",
    "            'epoch':None,\n",
    "            'model_state_dict':None ,\n",
    "            'optimizer_state_dict':None,\n",
    "            'loss':None ,\n",
    "            'cost':[],\n",
    "            'accuracy':[]}\n",
    "n_epochs = 5\n",
    "\n",
    "N_test = len(validation_dataset)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    counter = 0\n",
    "    cost=0\n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        z = model_r(x)\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter = counter+1\n",
    "      \n",
    "            \n",
    "        checkpoint_rotated['epochs']=n_epochs\n",
    "        checkpoint_rotated['model_state_dict']=model.state_dict()\n",
    "        checkpoint_rotated['optimizer_state_dict']= optimizer.state_dict()\n",
    "        checkpoint_rotated['loss']=loss\n",
    "        cost+=loss.item()\n",
    "        \n",
    "     \n",
    "            \n",
    "    correct = 0\n",
    "        \n",
    "        #perform a prediction on the validation  data  \n",
    "    for x_test, y_test in validation_loader:\n",
    "        z = model_r(x_test)\n",
    "        _, yhat = torch.max(z.data, 1)\n",
    "        correct += (yhat == y_test).sum().item()\n",
    "    accuracy = correct / N_test\n",
    "    print(accuracy)\n",
    "    checkpoint_rotated['cost'].append(cost) \n",
    "    checkpoint_rotated['accuracy'].append(accuracy)\n",
    "    torch.save(checkpoint_rotated,file_rotated) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Result\">Analyze Results</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we load the checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_rotated= torch.load(os.path.join(os.getcwd(),'rotated_data.pt'))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot accuracy and cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_accuracy(checkpoint_rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "five misclassified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_r.load_state_dict(checkpoint_rotated['model_state_dict'])\n",
    "model.eval()\n",
    "plot_mis_classified(model_r,validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_bottom\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/notebook_bottom%20.png\" width=\"750\" alt=\"PyTorch Bottom\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to Magnus <a href=\"http://www.hvass-labs.org/\">Erik Hvass Pedersen</a> whose tutorials helped me understand convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
